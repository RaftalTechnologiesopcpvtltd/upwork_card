{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import multiprocessing\n",
    "import traceback  # Import traceback module\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "from selenium_stealth import stealth\n",
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from dictionary_normanlizer import *\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import undetected_chromedriver as uc\n",
    "from selenium_stealth import stealth\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "\n",
    "from logger import *\n",
    "\n",
    "facebook_scrapper_logger = setup_logger(\"facebook_scrapper_logger\")\n",
    "\n",
    "\n",
    "def initializeProfile_driver():\n",
    "    # Define the ChromeDriver path (update this with your actual path)\n",
    "    CHROMEDRIVER_PATH = r\"landingpage\\Scrappers\\chromedriver.exe\"  # Change this accordingly\n",
    "\n",
    "    # Create a temporary directory for ChromeDriver\n",
    "    temp_dir = tempfile.mkdtemp(prefix=\"chrome_instance_\")\n",
    "    driver_folder = os.path.join(temp_dir, \"chromedriver\")\n",
    "    os.makedirs(driver_folder, exist_ok=True)\n",
    "\n",
    "    # Copy ChromeDriver to the temp directory\n",
    "    driver_path = shutil.copy(CHROMEDRIVER_PATH, driver_folder)\n",
    "\n",
    "    # Use the local Chrome profile directory in your PWD\n",
    "    profile_path = os.path.join(os.getcwd(), \"profile\", \"john\")\n",
    "\n",
    "    # Set up Chrome options\n",
    "    options = uc.ChromeOptions()\n",
    "\n",
    "    options.add_argument(f\"--user-data-dir={profile_path}\")  # Set the user data directory  # Use local profile\n",
    "    # options.add_argument(f\"--profile-directory={PROFILE_NAME}\")  # Ensure the correct profile is used\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    # options.add_argument(\"--headless=new\")  # New headless mode\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "    # Generate a random user-agent\n",
    "    ua = UserAgent()\n",
    "    options.add_argument(f\"user-agent={ua.random}\")\n",
    "\n",
    "    # Initialize undetected_chromedriver with copied ChromeDriver\n",
    "    driver = uc.Chrome(driver_executable_path=driver_path, options=options)\n",
    "\n",
    "    # Apply Selenium Stealth\n",
    "    stealth(driver,\n",
    "        languages=[\"en-US\", \"en\"],\n",
    "        vendor=\"Google Inc.\",\n",
    "        platform=\"Win32\",\n",
    "        webgl_vendor=\"Intel Inc.\",\n",
    "        renderer=\"Intel Iris OpenGL Engine\",\n",
    "        fix_hairline=True\n",
    "    )\n",
    "    return driver\n",
    "def fb_login(driver):\n",
    "    try:\n",
    "        driver.get(\"https://www.facebook.com/marketplace\")\n",
    "        time.sleep(3)\n",
    "        close_btn = driver.find_element(By.CSS_SELECTOR,'div[aria-label=\"Close\"]')\n",
    "        close_btn.click()\n",
    "        time.sleep(3)\n",
    "        email_input = driver.find_element(By.CSS_SELECTOR,'input[name=\"email\"]')\n",
    "        email_input.send_keys(\"johnhendersonsmith989@gmail.com\")\n",
    "        time.sleep(3)\n",
    "        pasword_input = driver.find_element(By.CSS_SELECTOR,'input[name=\"pass\"]')\n",
    "        pasword_input.send_keys(\"Test@1234\")\n",
    "        time.sleep(3)\n",
    "        login_btn = driver.find_element(By.CSS_SELECTOR,'div[aria-label=\"Log in\"]').find_elements(By.TAG_NAME,'span')\n",
    "        login_btn[-1].click()\n",
    "        time.sleep(3)\n",
    "    except:\n",
    "        facebook_scrapper_logger.info(\"Already Login\")\n",
    "\n",
    "def get_face_prod_links(driver):\n",
    "    driver.get(\"https://www.facebook.com/marketplace\")\n",
    "    search_url = driver.current_url+\"/search/?query=treck%20bike\"\n",
    "    driver.get(search_url)\n",
    "    prod_links = []\n",
    "    for i in range(0,10):\n",
    "        try:\n",
    "            facebook_scrapper_logger.info(i)\n",
    "            # Find the element (change XPath accordingly)\n",
    "            element = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div[2]/div/div')))\n",
    "            prod_cards = element.find_elements(By.CSS_SELECTOR,'a[class=\"x1i10hfl xjbqb8w x1ejq31n xd10rxx x1sy0etr x17r0tee x972fbf xcfux6l x1qhh985 xm0m39n x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1heor9g xkrqix3 x1sur9pj x1s688f x1lku1pv\"]')\n",
    "            # Scroll the element into view\n",
    "            for href in prod_cards:\n",
    "                try:\n",
    "                    facebook_scrapper_logger.info(\"in\")\n",
    "                    prod_links.append(href.get_attribute('href'))\n",
    "                except:\n",
    "                    pass\n",
    "            # Optional: Small delay to simulate real scrolling\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", prod_cards[-1])\n",
    "            driver.implicitly_wait(1)\n",
    "\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            facebook_scrapper_logger.info(\"No more elements found or scrolling stopped.\")\n",
    "            break  # Exit loop when no more elements are found\n",
    "    return prod_links\n",
    "\n",
    "def clean_description(description):\n",
    "    \"\"\"Clean the product description by removing HTML tags, <br> tags, and extra spaces.\"\"\"\n",
    "    if not description:\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(description, \"html.parser\")\n",
    "\n",
    "    # Replace <br> and other break elements with newlines\n",
    "    for br in soup.find_all([\"br\", \"p\", \"div\"]):  \n",
    "        br.replace_with(\"\\n\")\n",
    "\n",
    "    text = soup.get_text(separator=\" \")  # Extract text while maintaining spacing\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize multiple spaces/newlines to a single space\n",
    "    return text.strip()\n",
    "\n",
    "def save_to_csv(data, filename=r\"facebook_data.csv\"):\n",
    "    \"\"\"Save product data to a CSV file.\"\"\"\n",
    "    file_exists = os.path.exists(filename)\n",
    "\n",
    "    with open(filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=data.keys())\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow(data)\n",
    "\n",
    "    facebook_scrapper_logger.info(f\"Data saved to {filename}\")\n",
    "\n",
    "def get_face_prod(driver,prod_links):\n",
    "    for links in prod_links:\n",
    "        driver.get(links)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        title = soup.find(\"h1\").text.strip()\n",
    "        link = links\n",
    "\n",
    "        # Find all images where 'alt' contains the product title\n",
    "        filtered_images = [\n",
    "            img.get(\"src\") for img in soup.find_all(\"img\")\n",
    "            if img.get(\"alt\") and title.lower() in img.get(\"alt\").lower()\n",
    "        ]\n",
    "        price_info = soup.find(\"span\",class_=\"x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x xudqn12 x676frb x1lkfr7t x1lbecb7 xk50ysn xzsf02u\").text.strip().split('Â·')\n",
    "        description = clean_description(soup.find(\"div\",class_=\"xz9dl7a x4uap5 xsag5q8 xkhd6sd x126k92a\").text.strip())\n",
    "        if 'Condition' in soup.find(\"div\",class_=\"x1cy8zhl x78zum5 x1qughib x1y1aw1k x4uap5 xwib8y2 xkhd6sd\").text:\n",
    "            condition = soup.find(\"span\",class_=\"x1e558r4 xp4054r x3hqpx7\").text.strip()\n",
    "        price = price_info[0].strip()\n",
    "        price_text = price.strip()\n",
    "\n",
    "        # Use regex to extract the first price\n",
    "        match = re.findall(r'\\$\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?', price_text)  # Find all prices like $25, $40\n",
    "        if match:\n",
    "            actual_price = match[0]  # First one is the actual price\n",
    "        try:\n",
    "            Status = price_info[1].strip()\n",
    "        except:\n",
    "            Status = \"-\"\n",
    "        images = filtered_images\n",
    "        # facebook_scrapper_logger.info the filtered image URLs\n",
    "        prod_data = normalize_data({\n",
    "            \"Website Name\": \"Facebook\",\n",
    "            \"Website URL\": \"https://www.facebook.com/marketplace\",\n",
    "            \"Product Link\": link,\n",
    "            \"Product Images\": images,\n",
    "            \"Selling Type\" : \"Fixed\",\n",
    "            \"Product Title\": clean_description(title),\n",
    "            \"Product Price Currency\": \"$\",\n",
    "            \"Product Price\": actual_price,\n",
    "            \"Description\": description,\n",
    "            \"Condition\": condition,\n",
    "            \"Status\" : Status,\n",
    "        })\n",
    "        save_to_csv(prod_data, filename=r\"facebook_data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'landingpage\\\\Scrappers\\\\chromedriver.exe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43minitializeProfile_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     fb_login(driver)\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36minitializeProfile_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(driver_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Copy ChromeDriver to the temp directory\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m driver_path \u001b[38;5;241m=\u001b[39m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHROMEDRIVER_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Use the local Chrome profile directory in your PWD\u001b[39;00m\n\u001b[0;32m     48\u001b[0m profile_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjohn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:435\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    434\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 435\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'landingpage\\\\Scrappers\\\\chromedriver.exe'"
     ]
    }
   ],
   "source": [
    "driver = initializeProfile_driver()\n",
    "try:\n",
    "    fb_login(driver)\n",
    "except:\n",
    "    pass\n",
    "prod_links = get_face_prod_links(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    get_face_prod(driver,prod_links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
